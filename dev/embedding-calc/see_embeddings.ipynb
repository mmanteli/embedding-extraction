{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking how the query affects the results\n",
    "\n",
    "Idea of these query models is to create embeddings in a way that you prepend a query to the input. Here the idea is to see that if a query is prepended to the first text, how does it affect the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install torch\n",
    "! pip -q install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/mynttiam/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the document embeddings match\n",
      "True\n",
      "Do the query embeddings match\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "BTM = torch.load(\"e5_BitextMining.pt\")\n",
    "STS = torch.load(\"e5_STS.pt\")\n",
    "\n",
    "num_queries = 4  # known from previous\n",
    "\n",
    "print(\"Do the document embeddings match\")\n",
    "print(torch.equal(BTM[num_queries:], STS[num_queries:]))\n",
    "print(\"Do the query embeddings match\")\n",
    "print(torch.equal(BTM[:num_queries], STS[:num_queries]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "It does not affect the others. Conclusions:\n",
    "\n",
    "1. Prepend to all\n",
    "2. Prepend to none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format: pickle\n",
    "\n",
    "Testing if the pickle format results in readable material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '31fee4af60302d9b3b675b580fa71615', 'offset': 0, 'register': ['nb', 'NA'], 'text': 'It’s time to announce our most recent winners!', 'embeddings': array([ 0.02332607,  0.03185335, -0.00611989, ..., -0.01308386,\n",
      "       -0.05798069, -0.03886978], dtype=float32)}\n",
      "{'id': '31fee4af60302d9b3b675b580fa71615', 'offset': 46, 'register': ['nb', 'NA'], 'text': 'CONGRATS!!', 'embeddings': array([ 0.02012852,  0.03665633,  0.00868816, ..., -0.03004357,\n",
      "       -0.04968041,  0.01312306], dtype=float32)}\n",
      "{'id': '31fee4af60302d9b3b675b580fa71615', 'offset': 56, 'register': ['nb', 'NA'], 'text': 'Thank-you everyone for participating in these giveaways!', 'embeddings': array([-0.00732888,  0.00781527,  0.0146101 , ..., -0.03166147,\n",
      "       -0.05359244,  0.01492685], dtype=float32)}\n",
      "{'id': '31fee4af60302d9b3b675b580fa71615', 'offset': 112, 'register': ['nb', 'NA'], 'text': 'The winner of our Loving Your Pet Giveaway Hop for a Pet Safety Plaque from BoRegards is Entry #376: Kyona\\nTod’s Leather Bag (Week 3 of Win this Bag) Whitney F. is a winner!', 'embeddings': array([-0.01199353,  0.01280597, -0.04033489, ..., -0.02681436,\n",
      "       -0.05909019, -0.00508248], dtype=float32)}\n",
      "{'id': '31fee4af60302d9b3b675b580fa71615', 'offset': 285, 'register': ['nb', 'NA'], 'text': 'XBox Kinect Bundle Winner: Entry #130533 Victoria O.\\nSmokin Summer Giveaway Winner: Entry #56492 Helene T.', 'embeddings': array([-0.00227884,  0.00736943, -0.03317127, ..., -0.02071922,\n",
      "       -0.05617353, -0.02384568], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "num_files=0\n",
    "with open(\"../testi.pkl\", \"rb\") as f:\n",
    "    while True:\n",
    "        dataset = pickle.load(f)\n",
    "        num_files += 1\n",
    "        for d in dataset:\n",
    "            print(d)\n",
    "        break\n",
    "        #print(num_files)\n",
    "        #except:\n",
    "        #    print(num_files)\n",
    "        #break\n",
    "        #print(dataset)\n",
    "        #for d in dataset:\n",
    "        #    print(d)\n",
    "        #print(\"-------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting\n",
    "\n",
    "Options: define on model-level, define in encode() or modify input texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = []\n",
    "with open(\"../testi_prompt_in_encode.pkl\", \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            dataset = pickle.load(f)\n",
    "            #print(dataset)\n",
    "            for d in dataset:\n",
    "                emb1.append(d[\"embeddings\"])\n",
    "        except EOFError:\n",
    "            break\n",
    "emb2 = []\n",
    "with open(\"../testi_prompt_in_text.pkl\", \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            dataset = pickle.load(f)\n",
    "            #print(dataset)\n",
    "            for d in dataset:\n",
    "                emb2.append(d[\"embeddings\"])\n",
    "        except EOFError:\n",
    "            break\n",
    "emb3 = []\n",
    "with open(\"../testi_prompt_in_model.pkl\", \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            dataset = pickle.load(f)\n",
    "            #print(dataset)\n",
    "            for d in dataset:\n",
    "                emb3.append(d[\"embeddings\"])\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00484627,  0.00428783, -0.00206267, ..., -0.04010882,\n",
      "       -0.01950641,  0.01938101], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32)]\n",
      "[array([ 0.00106434,  0.0115186 , -0.00410124, ..., -0.02769748,\n",
      "       -0.05384639,  0.02348485], dtype=float32), array([ 0.00958741,  0.00609514,  0.02108929, ..., -0.01749452,\n",
      "       -0.03314401,  0.00367272], dtype=float32), array([ 0.00156308,  0.0039536 , -0.00868536, ..., -0.04427195,\n",
      "       -0.02533951,  0.0209051 ], dtype=float32), array([ 0.00958741,  0.00609514,  0.02108929, ..., -0.01749452,\n",
      "       -0.03314401,  0.00367272], dtype=float32), array([ 0.00106434,  0.0115186 , -0.00410124, ..., -0.02769748,\n",
      "       -0.05384639,  0.02348485], dtype=float32), array([ 0.00958741,  0.00609514,  0.02108929, ..., -0.01749452,\n",
      "       -0.03314401,  0.00367272], dtype=float32), array([ 0.00106434,  0.0115186 , -0.00410124, ..., -0.02769748,\n",
      "       -0.05384639,  0.02348485], dtype=float32), array([ 0.00958741,  0.00609514,  0.02108929, ..., -0.01749452,\n",
      "       -0.03314401,  0.00367272], dtype=float32), array([ 0.00106434,  0.0115186 , -0.00410124, ..., -0.02769748,\n",
      "       -0.05384639,  0.02348485], dtype=float32), array([ 0.00958741,  0.00609514,  0.02108929, ..., -0.01749452,\n",
      "       -0.03314401,  0.00367272], dtype=float32)]\n",
      "[array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00484627,  0.00428783, -0.00206267, ..., -0.04010882,\n",
      "       -0.01950641,  0.01938101], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32), array([ 0.00039106,  0.00255844, -0.00853562, ..., -0.03452792,\n",
      "       -0.05194162,  0.01749831], dtype=float32), array([ 0.00942401,  0.00212771,  0.01664995, ..., -0.02239172,\n",
      "       -0.03557405, -0.00034743], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(emb1)\n",
    "print(emb2)\n",
    "print(emb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result:\n",
    "\n",
    "Putting the prompt in the text results in different behaviour, while putting it in encode or model definition is the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
